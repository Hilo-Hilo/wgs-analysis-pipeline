name: WGS Pipeline Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    # Run tests weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'

env:
  PYTHON_VERSION: '3.11'
  CONDA_ENV: 'wgs_analysis'
  # Retry settings for transient network failures
  RETRY_MAX_ATTEMPTS: 3
  RETRY_DELAY_SECONDS: 10

jobs:
  shellcheck-lint:
    name: ShellCheck Lint
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install ShellCheck
        run: |
          sudo apt-get update
          sudo apt-get install -y shellcheck

      - name: Run ShellCheck on shell scripts
        shell: bash
        run: |
          mapfile -t shell_scripts < <(find . -type f -name "*.sh" -not -path "./.git/*" | sort)

          if [[ ${#shell_scripts[@]} -eq 0 ]]; then
            echo "No shell scripts found."
            exit 0
          fi

          printf 'Checking %s\n' "${shell_scripts[@]}"
          shellcheck -S error -e SC2034,SC2155,SC2086 "${shell_scripts[@]}"

  dependency-validation:
    name: Dependency Policy Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate DEPENDENCIES.md exists
        run: |
          if [[ ! -f DEPENDENCIES.md ]]; then
            echo "‚ùå DEPENDENCIES.md not found"
            exit 1
          fi
          echo "‚úÖ DEPENDENCIES.md found"

      - name: Validate dependency script syntax
        run: |
          bash -n scripts/validate_deps.sh
          echo "‚úÖ validate_deps.sh syntax OK"

      - name: Run dependency validator (CI mode)
        run: |
          # CI mode: validate runtime deps, skip bioinformatics tools
          bash scripts/validate_deps.sh --ci-mode --verbose

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [shellcheck-lint, dependency-validation]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run unit tests (no conda/toolchain)
        run: bash tests/run_tests.sh --unit-only

  unit-tests-matrix:
    name: Unit Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    needs: [shellcheck-lint]
    strategy:
      fail-fast: false
      matrix:
        # Keep Linux + macOS coverage; ubuntu-20.04 has shown repeated queue deadlocks.
        os: [ubuntu-22.04, macos-14]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run unit tests
        run: bash tests/run_tests.sh --unit-only

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [unit-tests]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Miniconda with retry
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          activate-environment: ${{ env.CONDA_ENV }}
          environment-file: .github/conda/integration-environment.yml
          channels: conda-forge,bioconda
          conda-remove-defaults: true
          channel-priority: flexible
          use-mamba: true
        env:
          # Longer timeout for conda operations
          MAMBA_NO_BANNER: '1'

      - name: Verify bioinformatics toolchain
        shell: bash -el {0}
        run: |
          echo "üîç Verifying installed tools..."
          fastqc --version || true
          fastp --version || true
          bwa-mem2 version || true
          samtools --version || true
          bcftools --version || true

      - name: Validate dependency versions
        shell: bash -el {0}
        run: |
          echo "üìã Running dependency version validation..."
          bash scripts/validate_deps.sh --verbose

      - name: Run full test suite
        shell: bash -el {0}
        run: bash tests/run_tests.sh

      - name: Upload integration test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-outputs-integration
          path: |
            /tmp/wgs_pipeline_test_*/
            tests/sample_data/
          retention-days: 7

  docker:
    name: Docker Build & Test
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image with retry
        run: |
          # Retry function for transient failures
          retry_with_backoff() {
            local max_attempts="$1"
            local delay="$2"
            shift 2
            local attempt=1
            while true; do
              echo "Attempt $attempt/$max_attempts: $*"
              if "$@"; then
                return 0
              fi
              if [[ $attempt -ge $max_attempts ]]; then
                echo "‚ùå Failed after $max_attempts attempts"
                return 1
              fi
              echo "‚ö†Ô∏è Attempt $attempt failed, retrying in ${delay}s..."
              sleep "$delay"
              attempt=$((attempt + 1))
              delay=$((delay * 2))
            done
          }

          echo "üê≥ Building Docker image..."
          retry_with_backoff 3 15 docker build \
            --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
            --build-arg BUILD_VERSION=${{ github.sha }} \
            --build-arg VCS_REF=${{ github.sha }} \
            -t wgs-pipeline:test .

      - name: Test Docker image
        run: |
          echo "üß™ Testing Docker image..."

          # Test that the image runs
          docker run --rm wgs-pipeline:test check_requirements.sh --help

          # ENTRYPOINT already executes inside conda env (wgs_analysis)
          docker run --rm wgs-pipeline:test fastqc --version
          docker run --rm wgs-pipeline:test fastp --version
          docker run --rm wgs-pipeline:test bash -lc "bwa-mem2 version | head -1"
          docker run --rm wgs-pipeline:test bash -lc "samtools --version | head -1"
          docker run --rm wgs-pipeline:test bash -lc "bcftools --version | head -1"

          # Run dependency validation inside container
          echo "üìã Validating dependency versions in container..."
          docker run --rm wgs-pipeline:test bash -c "bash scripts/validate_deps.sh --verbose"

          echo "‚úÖ Docker image tests passed!"

      - name: Smoke test Docker compose
        run: |
          # Quick smoke test of docker-compose config
          docker compose config > /dev/null
          echo "‚úÖ Docker Compose config is valid"

  docs:
    name: Documentation Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check documentation files
        run: |
          echo "üìö Checking documentation..."

          # Check that required documentation exists
          required_docs=(
            "README.md"
            "DEPENDENCIES.md"
            "docs/README.md"
            "docs/architecture/codebase-overview.md"
            "docs/guides/getting-started.md"
            "docs/guides/troubleshooting.md"
            "docs/reference/sample-registry.md"
          )

          for doc in "${required_docs[@]}"; do
            if [[ -f "$doc" ]]; then
              echo "‚úÖ Found: $doc"
            else
              echo "‚ùå Missing: $doc"
              exit 1
            fi
          done

          # Basic broken-link scan for local .md references
          find . -type f -name '*.md' -not -path './.git/*' -print0 | \
            xargs -0 grep -ohE '\]\([^)]+\.md[^)]*\)' | \
            sed -E 's/\]\(([^)#?]+).*/\1/' | sort -u | while read -r link; do
              if [[ ! -f "$link" ]]; then
                echo "‚ö†Ô∏è Potentially broken link: $link"
              fi
            done

          echo "üìñ Documentation check completed!"

  benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    needs: [integration-tests]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: ${{ env.PYTHON_VERSION }}
          channels: conda-forge,bioconda
          conda-remove-defaults: true
          channel-priority: flexible
          use-mamba: true

      - name: Install tools
        shell: bash -el {0}
        run: |
          conda create -n ${{ env.CONDA_ENV }} -c conda-forge -c bioconda \
            python=${{ env.PYTHON_VERSION }} fastqc fastp -y
          conda activate ${{ env.CONDA_ENV }}

      - name: Run performance benchmark
        shell: bash -el {0}
        run: |
          conda activate ${{ env.CONDA_ENV }}

          echo "‚ö° Running performance benchmark..."
          mkdir -p logs
          python3 tests/generate_sample_data.py --num-reads 10000 --output-dir benchmark_data

          # Time the quality control step
          time_start=$(date +%s)
          scripts/quality_control.sh \
            --input-dir benchmark_data \
            --output-dir benchmark_results \
            --threads 2
          time_end=$(date +%s)

          duration=$((time_end - time_start))
          echo "üìä QC completed in ${duration} seconds for 10,000 reads"

          # Store benchmark result
          echo "benchmark_duration_seconds: $duration" > benchmark_results.txt
          echo "benchmark_reads: 10000" >> benchmark_results.txt
          echo "benchmark_date: $(date -u)" >> benchmark_results.txt

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            benchmark_results.txt
            benchmark_results/
          retention-days: 30

  # Dependency freshness check (weekly)
  dependency-freshness:
    name: Dependency Freshness
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check for outdated dependencies
        run: |
          echo "üîÑ Checking dependency freshness..."
          echo ""
          echo "Current version ranges in DEPENDENCIES.md:"
          grep -E "^\| \`" DEPENDENCIES.md | head -10 || true
          echo ""
          echo "‚ÑπÔ∏è Manual review recommended for version updates"
          echo "See: https://bioconda.github.io/recipes.html"
